\chapter{Discussion}
\begin{center}
\vspace{-6ex}
\textit{"From a to z"}
\vspace{6ex}
\end{center}

Even though the Quadratic Discriminant is a rather simple algorithm with many assumptions, it produces good results. The results obtained are very close to those of M. Andersson in his master's thesis, and since we had the same approach, both in features and algorithm, this is expected. Exactly the same results was not found and might be due for example that we do not segment the plant and background in the same way. Somewhat less apparent is that the gain from switching to the more complex model of neural networks did not yield in that much of a accuracy difference. Even though it may separate the data using complex boundaries it seems that the simpler the better. This can especially be seen in the number of hidden layers used, the networks which consistently produced the best results was with the single hidden layer. This can be due to several different parts, for depending on the data itself and also on the model. In Chapter.~\ref{chap:machine} we discussed the uses of having multiple layers in a neural network, mostly due to complex decision boundaries and abstract patterns in the data. The good performance of the single hidden layered network might suggest that the data actually are clustered rather simple and can be separated using only somewhat complex boundaries. One way to actually see this would be to plot the different features against each other and see how well the different groups clusters. There could also be problems in the training process of the network. During each training instance, we train the network by applying gradient descent on the network, layer by layer. Since gradient descent always moves in the most descending direction it is very easy to get stuck in a local optimum which is a problem that increases with the number of layers, as the energy function propagates through many non-linear activation functions throughout the training. This could be, maybe not avoided entirely, but the performance might increase by using some kinds of stochasticity in the gradient decent, or introduce momentum in the update rule. This is what could have been changed for the data that is present, but maybe the single biggest bottleneck is amount of data availiable. Even though the data could be separated using complex boundires, these dependencies can not be visualized with this data. Also, since the data set is so small, there is no way to really determine what data points are special due to being a new representation of the group or just noisy data. If the model would correctly classify this data, then it would probably be seen as overfitting, whilst it actually is represenative for a subgroup of the given class.  \\

The second data set was separated into the three different groups, background, plant, and weed rather well with a high correlation between the estimated densities and the ground truth. Since we only used the pixels color information for this data set, expanding this model to use object features for classification might prove very useful, since we take into account for local information as well. The high accuracy in the segmentation suggest that we could combine the approaches for the two data sets to create a more general classification model. Though, the segmentation of single plants are still not present for this method, so using a more sophisticated model might a better usage of time, e.g. the CNN, as it combines both the local and the regional information of the images. Moreover, the limitation of this algorithm lies, not in the data itself, but the inaccuracy of the classification of it. The classification of the data is made by me with my limited knowledge in agronomy. This is also one of the reasons why a supervised model for the second data set was not used, since if the data labeling is not completely correct, the algorithm will probably learn some strange boundires in groups of data that actually represents the same thing. If the opposite way, of first grouping the data, and then classify the groups, the missclassification of the training data is not as destructive.\\

All in all, the methods discussed in this thesis could be useful in creating a program which helps a farmer finding where the crops field require most herbicides. If several images taken in sequence, e.g. with a camera mounted on a tractor, similar to the images in the second data set, over the field are stitched together (something not discussed in this thesis) and the k-means clustering are performed on the result, an estimate of the density of the weeds in the field can be given.
